import os
import json
import pickle
from tqdm import tqdm
import re
import pdb
from collections import Counter
from textwrap import dedent
import numpy as np
from rdp import rdp as rdp_simplify
def clean_action(text: str):
    """æ¸…æ´—åŠ¨ä½œï¼šå» markdownã€å»ç©ºæ ¼ã€å» theã€ç»Ÿä¸€å°å†™"""
    if text is None:
        return ""

    t = text.strip()
    t = t.strip("*_`")                   # å» markdown
    t = t.lower()

    # ğŸ”¥ è‡ªåŠ¨ä¿®æ­£å¸¸è§ç”Ÿæˆé”™è¯¯ï¼Œä¾‹å¦‚å¸¦ "the"
    t = t.replace(" to the right", " to right")
    t = t.replace(" to the left", " to left")

    # å†å¤„ç†å¯èƒ½å‡ºç°çš„å¤šä½™ç©ºæ ¼
    t = re.sub(r"\s+", " ", t).strip()

    return t

import re

def opencv_to_bev(
    uv_or_uvz,
    W=500, H=1000, Z=40,
    x_min=-50, x_max=50,
    y_min=-25, y_max=25,
    z_min=-2.3, z_max=17
):
    """
    OpenCV (u, v[, z]) â†’ BEV åæ ‡
    - è¾“å…¥ (N, 2): (u, v)      â†’ è¾“å‡º (x, y)
    - è¾“å…¥ (N, 3): (u, v, z)   â†’ è¾“å‡º (x, y, z)
    """
    pts = np.asarray(uv_or_uvz, dtype=np.float32)

    if pts.ndim != 2 or pts.shape[1] not in (2, 3):
        raise ValueError(
            f"Expected shape (N, 2) or (N, 3), got {pts.shape}"
        )

    u = pts[:, 0]
    v = pts[:, 1]

    # -------- u, v â†’ x, y --------
    # y æ–¹å‘ï¼ˆæ³¨æ„ bev_to_opencv ä¸­ y è¢«å–äº†è´Ÿå·ï¼‰
    y = u / W * (y_max - y_min) + y_min
    y = -y

    # x æ–¹å‘
    x = x_max - v / H * (x_max - x_min)

    # -------- æ˜¯å¦å¤„ç† z --------
    if pts.shape[1] == 3:
        z_pix = pts[:, 2]
        z = z_pix / Z * (z_max - z_min) + z_min
        bev =  np.stack([x, y, z], axis=1)
    else:
        bev =  np.stack([x, y], axis=1)
    return np.round(bev, 1)
def _match_valid_prefix(action_cleaned: str, valid_options_lower):
    """
    åœ¨ä¸€ä¸ªå¯èƒ½å¸¦è§£é‡Šçš„é•¿å­—ç¬¦ä¸²ä¸­ï¼Œæ‰¾â€œå‰ç¼€æ˜¯åˆæ³•åŠ¨ä½œâ€çš„æƒ…å†µï¼š
    ä¾‹å¦‚ï¼š
        "move forward â€” the vehicle ..."  -> "move forward"
        "turn right: the ego ..."         -> "turn right"
    """
    if not action_cleaned:
        return None

    # å…ˆæŠŠå¸¸è§åˆ†éš”ç¬¦å‰çš„éƒ¨åˆ†å•ç‹¬æ‹¿å‡ºæ¥ï¼Œå¢åŠ æˆåŠŸç‡
    # æ¯”å¦‚ 'move forward â€” xxx' -> 'move forward'
    #      'turn left: xxx'     -> 'turn left'
    for sep in ["â€”", "-", ":", "ï¼›", ";", "ï¼Œ", ","]:
        if sep in action_cleaned:
            action_cleaned = action_cleaned.split(sep, 1)[0].strip()
            break

    # å†æŒ‰é•¿åº¦ä»é•¿åˆ°çŸ­ï¼Œåšå‰ç¼€åŒ¹é…
    for opt in sorted(valid_options_lower, key=len, reverse=True):
        if action_cleaned.startswith(opt):
            return opt

    # å¦‚æœå‰ç¼€æ²¡åŒ¹é…ä¸Šï¼Œå†ç›´æ¥è¯•ä¸€ä¸‹â€œå®Œå…¨ç­‰äºâ€
    if action_cleaned in valid_options_lower:
        return action_cleaned

    return None

def extract_actions_from_cot(cot: str, segment_id_index: str, timestamp_index: str):
    """
    ä» CoT å­—ç¬¦ä¸²ä¸­æå– Lateral / Longitudinal actionã€‚
    å¦‚æœè§£æå¤±è´¥æˆ–ä¸åœ¨å…è®¸é›†åˆä¸­ï¼Œåˆ™è§¦å‘æ–­ç‚¹ã€‚
    """

    # å…ˆæŠŠæ‰€æœ‰ * å»æ‰ï¼Œé¿å… markdown å½±å“åŒ¹é…
    cot_clean = cot.replace("*", "")

    lat_match = re.search(
        r"Lateral\s+Actions?\s*:\s*([^\n\r]+)",
        cot_clean,
        flags=re.IGNORECASE,
    )

    lon_match = re.search(
        r"Longitudinal\s+Actions?\s*:\s*([^\n\r]+)",
        cot_clean,
        flags=re.IGNORECASE,
    )

    if not lat_match or not lon_match:
        print("âŒ æœªæ‰¾åˆ° Lateral/Longitudinal action è¡Œ")
        print("===== COT DUMP START =====")
        print(cot_clean)
        print("segment_id_index:", segment_id_index)
        print("timestamp_index:", timestamp_index)
        print("===== COT DUMP END =====")
        pdb.set_trace()  # å¡åœ¨è¿™é‡Œæ£€æŸ¥
        raise ValueError("Cannot find action lines in CoT.")

    # åŸå§‹å­—ç¬¦ä¸²ï¼ˆå¯èƒ½å¸¦è§£é‡Šï¼‰
    raw_lateral = lat_match.group(1).strip()
    raw_longitudinal = lon_match.group(1).strip()

    # å…ˆåšé€šç”¨æ¸…æ´—ï¼ˆå°å†™ã€å» the ç­‰ï¼‰
    lateral_cleaned = clean_action(raw_lateral)
    longitudinal_cleaned = clean_action(raw_longitudinal)

    # å†ä»ä¸­æŠ½å–â€œåˆæ³•åŠ¨ä½œå‰ç¼€â€
    lateral_action = _match_valid_prefix(lateral_cleaned, LATERAL_OPTIONS_LOWER)
    longitudinal_action = _match_valid_prefix(longitudinal_cleaned, LONGITUDINAL_OPTIONS_LOWER)

    # æ ¡éªŒæ˜¯å¦åœ¨å…è®¸é›†åˆä¸­
    if lateral_action is None:
        print("âŒ æœªè¯†åˆ«åˆ°åˆæ³•çš„ lateral action:")
        print(f"  raw     = '{raw_lateral}'")
        print(f"  cleaned = '{lateral_cleaned}'")
        print("å…è®¸å€¼ä¸º:", LATERAL_OPTIONS)
        print("segment_id_index:", segment_id_index)
        print("timestamp_index:", timestamp_index)
        pdb.set_trace()
        raise ValueError(f"Invalid lateral action (no valid prefix): {raw_lateral}")

    if longitudinal_action is None:
        print("âŒ æœªè¯†åˆ«åˆ°åˆæ³•çš„ longitudinal action:")
        print(f"  raw     = '{raw_longitudinal}'")
        print(f"  cleaned = '{longitudinal_cleaned}'")
        print("å…è®¸å€¼ä¸º:", LONGITUDINAL_OPTIONS)
        print("segment_id_index:", segment_id_index)
        print("timestamp_index:", timestamp_index)
        pdb.set_trace()
        raise ValueError(f"Invalid longitudinal action (no valid prefix): {raw_longitudinal}")

    # æ­¤æ—¶è¿”å›çš„æ˜¯â€œå½’ä¸€åŒ–åçš„å°å†™åˆæ³•åŠ¨ä½œâ€ï¼Œä¾‹å¦‚ "move forward", "turn left"
    return lateral_action, longitudinal_action

def load_annotations(ann_file):
    """Load annotation from a olv2 pkl file.

    Args:
        ann_file (str): Path of the annotation file.

    Returns:
        list[dict]: Annotation info from the json file.
    """
    with open(ann_file, 'rb') as f:
        data_infos = pickle.load(f)
    if isinstance(data_infos, dict):
        if True and split == 'train':
            data_infos = [
                info for info in data_infos.values()
                if info['meta_data']['source_id'] not in MAP_CHANGE_LOGS
            ]
        else:
            data_infos = list(data_infos.values())
    return data_infos



if __name__ == '__main__':

    CAMS = (
        'ring_front_center', 'ring_front_left', 'ring_front_right',
        'ring_rear_left', 'ring_rear_right', 'ring_side_left', 'ring_side_right'
    )
    LANE_CLASSES = ('lane_segment', 'ped_crossing')
    MAP_CHANGE_LOGS = [
        '75e8adad-50a6-3245-8726-5e612db3d165',
        '54bc6dbc-ebfb-3fba-b5b3-57f88b4b79ca',
        'af170aac-8465-3d7b-82c5-64147e94af7d',
        '6e106cf8-f6dd-38f6-89c8-9be7a71e7275',
    ]
    data_root = '/data_test/home/lizhen/yym/TopoStreamer_vlm/'
    ann_file = data_root + 'data_dict_subset_A_train_lanesegnet_reasoningv3.pkl'
    split = 'train'
    # å…è®¸çš„åŠ¨ä½œé›†åˆ
    LATERAL_OPTIONS = {
        "move forward",
        "turn left",
        "change lane to left",
        "turn right",
        "change lane to right",
    }

    LONGITUDINAL_OPTIONS = {
        "stop",
        "deceleration to zero",
        "maintain constant speed",
        "deceleration",
        "acceleration",
    }

    LATERAL_OPTIONS_LOWER = {x.lower() for x in LATERAL_OPTIONS}
    LONGITUDINAL_OPTIONS_LOWER = {x.lower() for x in LONGITUDINAL_OPTIONS}

    data_infos = load_annotations(ann_file)

    # lateral_counter = Counter()
    # longitudinal_counter = Counter()
    # pair_counter = Counter()   # (lateral, longitudinal) ç»„åˆçš„ç»Ÿè®¡ï¼Œå¯é€‰
    sharegpt_samples = []

    special_tokens = False
    for idx in tqdm(range(len(data_infos))):
        segment_id_index = str(data_infos[idx]['segment_id'])
        timestamp_index = str(data_infos[idx]['timestamp'])

        json_path = f"./data/Trainset/{segment_id_index}/{timestamp_index}/"
        with open(json_path + "lane_with_drive.json", "r", encoding="utf-8") as f:
            lane_data = json.load(f)
        for lane in lane_data['lanes']:
            if 'coords_2d' in lane:
                lane['point'] = lane.pop('coords_2d')
                lane['id'] = lane.pop('center_id')
                # lane['id'] = lane['id'].replace('LANE', 'L').replace('PED', 'P')
                
                lane_coord = lane['point']

            
                lane_coord =  lane_coord
       
                lane_coord = rdp_simplify(lane_coord, epsilon=3.0)
                lane_coord = np.array(lane_coord)
              
                lane_coord = [
                [int(x),  int(y)]
                for x, y in lane_coord[:, :2]

                ]       
                lane['point'] = lane_coord
                
                for k in ['category', 'left_boundary', 'right_boundary', 'offset']:
                    lane.pop(k, None)

        navigation_information = lane_data['navigation']
        del lane_data['future_waypoints']
        
        del lane_data['navigation']

        ### to do cot
        # with open(json_path + "TopoCot_without_thinking.json", "r", encoding="utf-8") as f:
        #     cot_data = json.load(f)
        #     cot = cot_data['answers']['all_pure_answer']

        # lateral_action, longitudinal_action = extract_actions_from_cot(cot, segment_id_index, timestamp_index)

        # lane_data['ego']['lateral_action'] = lateral_action
        # lane_data['ego']['longitudinal_action'] = longitudinal_action


 



        system_prompt = dedent("""
        - You are a traffic engineer and autonomous driving perception analyst.
        - The map spans a longitudinal range of 0 to 1000 decimeters and a lateral range of 0 to 500 decimeters.

        The coordinate system is defined as follows:
        - The origin [0, 0] is located at the top left corner of the map.
        - The ego vehicle is always positioned at the center point [250, 500].
        - The x-axis decreases toward the left side of the ego vehicle and increases toward the right side of the ego vehicle.
        - The y-axis decreases toward the front of the ego vehicle and increases toward the rear of the ego vehicle.

        â€¢ x < 250 â‡’ LEFT the ego vehicle; x > 250 â‡’ RIGHT the ego vehicle.
        â€¢ y < 500 â‡’ IN FRONT OF the ego vehicle; y > 500 â‡’ BEHIND of the ego vehicle.
        """).strip()

        Instruction_prompt = dedent(f"""
        Carefully predict the map information and lane topology in JSON format.""").strip()

        assistant_answer = (
            f"{json.dumps(lane_data, ensure_ascii=False)}"
        )

        sample = {
                    
                    "system": system_prompt,
                    "prompt": Instruction_prompt,
                    "answer": assistant_answer,
                },

        dir_path = f'./data/train_conv_rdp/{segment_id_index}/{timestamp_index}'
        os.makedirs(dir_path, exist_ok=True)

        out_path = os.path.join(dir_path, "bev_conv.json")

        with open(out_path, "w", encoding="utf-8") as f:
            json.dump(sample, f, ensure_ascii=False, indent=2)
        import pdb; pdb.set_trace()
