import json
import numpy as np
import matplotlib.pyplot as plt
from adjustText import adjust_text
import matplotlib.patheffects as pe  # å¯é€‰ï¼šç»™æ–‡å­—åŠ æè¾¹æ›´æ¸…æ™°
from matplotlib.lines import Line2D
import cv2
import os
import mmcv
import imageio.v2 as imageio
import copy
import pickle
import sys
from shapely.geometry import LineString
from pathlib import Path
import sys, os

from evaluate_custom_modified import lanesegnet_evaluate

COLOR_DICT = {  # RGB [0, 1]
    'centerline': np.array([243, 90, 2]) / 255,
    'laneline': np.array([0, 32, 127]) / 255,
    'ped_crossing': np.array([55, 126, 71]) / 255,
    'road_boundary': np.array([220, 30, 0]) / 255,
}
LINE_PARAM = {
    0: {'color': COLOR_DICT['laneline'], 'alpha': 0.3, 'linestyle': ':'},       # none
    1: {'color': COLOR_DICT['laneline'], 'alpha': 0.75, 'linestyle': 'solid'},  # solid
    2: {'color': COLOR_DICT['laneline'], 'alpha': 0.75, 'linestyle': '--'},     # dashed
    'ped_crossing': {'color': COLOR_DICT['ped_crossing'], 'alpha': 1, 'linestyle': 'solid'},
    'road_boundary': {'color': COLOR_DICT['road_boundary'], 'alpha': 1, 'linestyle': 'solid'}
}
BEV_RANGE = [-50, 50, -25, 25]

BOUNDARY_MAP = {
    "invisible": 0,
    "solid": 1,
    "dashed": 2,
}


scene_id = ['10145', '10125', '10104', '10018', '10019', '10090', '10141', '10016', '10091', '10116', '10127', '10051', '10066', '10078', '10102', '10029', '10069', '10087', '10043', '10083', '10138', '10134', '10026', '10011', '10079', '10130', '10093', '10117', '10131', '10132', '10006', '10118', '10084', '10049', '10147', '10114', '10062', '10082', '10033', '10148', '10144', '10017', '10124', '10094', '10120', '10068', '10143', '10031', '10008', '10115']

# æ˜¯å¦åªè®¡ç®—selectåœºæ™¯çš„æŒ‡æ ‡
USE_SELECT_SCENES = False  # è®¾ç½®ä¸ºTrueåˆ™åªè®¡ç®—scene_idåˆ—è¡¨ä¸­çš„åœºæ™¯ï¼ŒFalseåˆ™è®¡ç®—æ‰€æœ‰åœºæ™¯

def opencv_to_bev(
    uv_or_uvz,
    W=500, H=1000, Z=40,
    x_min=-50, x_max=50,
    y_min=-25, y_max=25,
    z_min=-2.3, z_max=17
):
    """
    OpenCV (u, v[, z]) â†’ BEV åæ ‡
    - è¾“å…¥ (N, 2): (u, v)      â†’ è¾“å‡º (x, y)
    - è¾“å…¥ (N, 3): (u, v, z)   â†’ è¾“å‡º (x, y, z)
    """
    pts = np.asarray(uv_or_uvz, dtype=np.float32)

    if pts.ndim != 2 or pts.shape[1] not in (2, 3):
        raise ValueError(
            f"Expected shape (N, 2) or (N, 3), got {pts.shape}"
        )

    u = pts[:, 0]
    v = pts[:, 1]

    # -------- u, v â†’ x, y --------
    # y æ–¹å‘ï¼ˆæ³¨æ„ bev_to_opencv ä¸­ y è¢«å–äº†è´Ÿå·ï¼‰
    y = u / W * (y_max - y_min) + y_min
    y = -y

    # x æ–¹å‘
    x = x_max - v / H * (x_max - x_min)

    # -------- æ˜¯å¦å¤„ç† z --------
    if pts.shape[1] == 3:
        z_pix = pts[:, 2]
        z = z_pix / Z * (z_max - z_min) + z_min
        return np.stack([x, y, z], axis=1)
    else:
        return np.stack([x, y], axis=1)

def compute_left_right_boundaries_2d(centerline: np.ndarray, offset: float):
    cl = np.asarray(centerline, dtype=np.float32)
    if cl.ndim != 2 or cl.shape[0] < 1 or cl.shape[1] != 2:
        raise ValueError(f"centerline must be (N,2), got {cl.shape}")

    # ===== 0. é€€åŒ–æƒ…å†µï¼šæ‰€æœ‰ç‚¹éƒ½ä¸€æ · =====
    if np.max(np.linalg.norm(cl - cl[0], axis=1)) < 1e-6:
        # ğŸ‘‰ ç›´æ¥ç”¨å›ºå®šæ–¹å‘åç§»ï¼ˆy è½´ï¼‰
        left_boundary  = cl + np.array([0.0,  offset], dtype=np.float32)
        right_boundary = cl - np.array([0.0,  offset], dtype=np.float32)
        return left_boundary, right_boundary

    # ===== 1. æ­£å¸¸æƒ…å†µï¼šæ•´ä½“æ–¹å‘ =====
    whole_direction = cl[-1] - cl[0]
    whole_direction /= (np.linalg.norm(whole_direction) + 1e-8)

    # å·¦æ³•å‘
    whole_orth = np.array([-whole_direction[1], whole_direction[0]], dtype=np.float32)
    if whole_orth[1] < 0:
        whole_orth = -whole_orth
    whole_orth /= (np.linalg.norm(whole_orth) + 1e-8)

    left_boundary = []
    right_boundary = []
    last_orth = whole_orth
    n = cl.shape[0]

    # ===== 2. é€æ®µ =====
    for i in range(n - 1):
        seg = cl[i + 1] - cl[i]
        seg_norm = np.linalg.norm(seg)
        if seg_norm < 1e-8:
            orth = last_orth
        else:
            d = seg / seg_norm
            orth = np.array([-d[1], d[0]], dtype=np.float32)
            if np.dot(orth, whole_orth) < 0:
                orth = -orth
            orth /= (np.linalg.norm(orth) + 1e-8)

        last_orth = orth
        left_boundary.append(cl[i] + orth * offset)
        right_boundary.append(cl[i] - orth * offset)

    # ===== 3. æœ«å°¾ç‚¹ =====
    left_boundary.append(cl[-1] + last_orth * offset)
    right_boundary.append(cl[-1] - last_orth * offset)

    return np.asarray(left_boundary), np.asarray(right_boundary)

def clean_and_validate_points(points):
    """
    æ¸…ç†å’ŒéªŒè¯ç‚¹æ•°æ®ï¼Œç¡®ä¿æ¯ä¸ªç‚¹éƒ½æ˜¯æœ‰æ•ˆçš„ [x, y] æ ¼å¼ã€‚
    è¿‡æ»¤æ‰æ— æ•ˆçš„ç‚¹ï¼ˆåªæœ‰ä¸€ä¸ªå…ƒç´ ã€æ ¼å¼ä¸æ­£ç¡®ç­‰ï¼‰ã€‚
    
    Args:
        points: ç‚¹åˆ—è¡¨ï¼Œå¯èƒ½æ˜¯ [[x1, y1], [x2, y2], ...] æˆ– [[x1, y1], [x2], ...] ç­‰æ ¼å¼
        
    Returns:
        np.ndarray: æ¸…ç†åçš„ç‚¹æ•°ç»„ï¼Œå½¢çŠ¶ä¸º (N, 2)ï¼Œå¦‚æœæ‰€æœ‰ç‚¹éƒ½æ— æ•ˆåˆ™è¿”å› None
    """
    if not points or len(points) == 0:
        return None
    
    cleaned_points = []
    for pt in points:
        # è½¬æ¢ä¸ºåˆ—è¡¨ä»¥ä¾¿å¤„ç†
        if isinstance(pt, (list, tuple, np.ndarray)):
            pt_list = list(pt) if not isinstance(pt, np.ndarray) else pt.tolist()
        else:
            continue
        
        # æ£€æŸ¥ç‚¹çš„æœ‰æ•ˆæ€§
        if len(pt_list) >= 2:
            # æœ‰è‡³å°‘ä¸¤ä¸ªå…ƒç´ ï¼Œå–å‰ä¸¤ä¸ªä½œä¸º x, y
            try:
                x, y = float(pt_list[0]), float(pt_list[1])
                cleaned_points.append([x, y])
            except (ValueError, TypeError):
                # æ— æ³•è½¬æ¢ä¸ºæµ®ç‚¹æ•°ï¼Œè·³è¿‡è¿™ä¸ªç‚¹
                continue
        elif len(pt_list) == 1:
            # åªæœ‰ä¸€ä¸ªå…ƒç´ ï¼Œå¯èƒ½æ˜¯æ ¼å¼é”™è¯¯ï¼Œè·³è¿‡
            continue
        else:
            # ç©ºç‚¹ï¼Œè·³è¿‡
            continue
    
    if len(cleaned_points) == 0:
        return None
    
    return np.array(cleaned_points, dtype=np.float32)

def fix_pts_interpolate(lane, n_points):
    """
    å¯¹è½¦é“çº¿ç‚¹è¿›è¡Œæ’å€¼ï¼Œç¡®ä¿æœ‰ n_points ä¸ªç‚¹ã€‚
    å¦‚æœåªæœ‰ä¸€ä¸ªç‚¹æˆ–çº¿æ®µé•¿åº¦ä¸º0ï¼Œè¿”å›è¯¥ç‚¹é‡å¤ n_points æ¬¡ã€‚
    """
    lane = np.asarray(lane)
    
    # å¤„ç†åªæœ‰ä¸€ä¸ªç‚¹æˆ–ç©ºç‚¹çš„æƒ…å†µ
    if len(lane) == 0:
        raise ValueError("Empty lane points")
    
    if len(lane) == 1:
        # åªæœ‰ä¸€ä¸ªç‚¹ï¼Œè¿”å›è¯¥ç‚¹é‡å¤ n_points æ¬¡
        single_point = lane[0]
        return np.tile(single_point, (n_points, 1))
    
    # å¤šä¸ªç‚¹çš„æƒ…å†µï¼Œä½¿ç”¨ LineString æ’å€¼
    ls = LineString(lane)
    
    # å¦‚æœçº¿æ®µé•¿åº¦ä¸º0ï¼ˆæ‰€æœ‰ç‚¹é‡åˆï¼‰ï¼Œä¹Ÿè¿”å›ç¬¬ä¸€ä¸ªç‚¹é‡å¤ n_points æ¬¡
    if ls.length < 1e-6:
        return np.tile(lane[0], (n_points, 1))
    
    distances = np.linspace(0, ls.length, n_points)
    lane_interpolated = np.array([ls.interpolate(distance).coords[0] for distance in distances])
    return lane_interpolated

def lanes_to_annotation(lanes):
    """
    æŠŠ eval_results é‡Œçš„ lanes(list) è½¬æˆ draw_annotation_bev_align_coord ç”¨çš„ annotation ç»“æ„
    - centerline: ç›´æ¥ç”¨ point_2d
    - ped_cross: å¡åˆ° area é‡Œï¼Œcategory = 1, points=[point_2d]
    """
    lane_segment = []
    areas = []

    for lane in lanes:
        cat = lane.get("category", "")
        pts = lane.get("point_2d", [])
        left_b = lane.get("left_boundary", "invisible")
        right_b = lane.get("right_boundary", "invisible")

        if not pts:
            continue

        if cat == "centerline":
            lane_segment.append(
                {
                    "centerline": pts,
                    # è¿™é‡Œç”¨åŒä¸€æ¡çº¿ä»£æ›¿å·¦å³è¾¹ç•Œï¼ˆåªæ˜¯ä¸ºäº†å¯è§†åŒ–ï¼Œä¸¥æ ¼å‡ ä½•ä½ å¯ä»¥ä¹‹åå†ç»†åŒ–ï¼‰
                    "left_laneline": pts,
                    "right_laneline": pts,
                    "left_laneline_type": BOUNDARY_MAP.get(left_b, 0),
                    "right_laneline_type": BOUNDARY_MAP.get(right_b, 0),
                    "confidence": 1,
                }
            )
        elif cat == "ped_cross":
            areas.append(
                {
                    "category": 1,    # ä½ çš„ _draw_area_align_coord é‡Œç”¨ category == 1 åˆ¤æ–­è¡Œäººè¿‡è¡—
                    "points": [pts],  # ä¿æŒå’Œä½ é‚£è¾¹ä¸€è‡´ï¼šarea['points'][0]
                    "confidence": 1,
                }
            )
        else:
            # å…¶ä»–ç±»åˆ«å…ˆå¿½ç•¥
            continue

    return {
        "lane_segment": lane_segment,
        "area": areas,
    }
def _draw_line_align_coord(ax, line, label=None, multi_color_laneline = False, color = None):

    if multi_color_laneline:

        points = np.asarray(line['points'])

        config = LINE_PARAM[line['linetype']]
        config['color'] = color
        ax.plot(points[:, 0], points[:, 1], linewidth=2, zorder=1, label=label, **config)
    else:
        points = np.asarray(line['points'])

        config = LINE_PARAM[line['linetype']]
        ax.plot(points[:, 0], points[:, 1], linewidth=2, zorder=1, label=label, **config)

def _draw_centerline_align_coord(ax, lane_centerline, label=None, iid = None, all_num = None, multi_color_centerline = False):
    points = np.asarray(lane_centerline['points'])

    color = COLOR_DICT['centerline']
    texts = []
    if multi_color_centerline:
        
        lane_name=f"{iid}"
        cmap = plt.get_cmap('tab20') 
        color = cmap(iid / max(1, all_num-1))
        # draw line
        try:
            ax.plot(points[:, 0], points[:, 1], color=color, alpha=1.0, linewidth=2, zorder=2, label=label)
        except Exception as e:
            print(f"âš ï¸ Error plotting centerline: {e}")
            pass
        # draw start and end vertex
        ax.scatter(points[[0, -1], 0], points[[0, -1], 1], color=color, s=10, zorder=3)
        # draw arrow

        ax.annotate('', xy=(points[-1, 0], points[-1, 1]),
                    xytext=(points[-2, 0], points[-2, 1]),
                    arrowprops=dict(arrowstyle='->', lw=2.0, color=color), zorder=3)
        # ax.text(points[4,1], points[4,0], lane_name, fontsize=8, color=color,
        #          ha='center', va='center', fontweight='bold', zorder=10, clip_on=False)
        mid = len(points)//2
        x, y = points[mid,0], points[mid,1]
        t = points[min(mid+1,len(points)-1)] - points[max(mid-1,0)]
        nx, ny = -t[0], t[1]
        nrm = np.hypot(nx,ny)+1e-6
        # x += 2.0*nx/nrm; y += 2.0*ny/nrm          # æ³•å‘åç§» 2 ä¸ªå•ä½
        x += np.random.uniform(-5,5)          # è½»å¾®éšæœºåˆå§‹åŒ–
        y += np.random.uniform(-5,5)

        txt = ax.text(x, y, lane_name,
                    fontsize=8, color=color,  # ç»Ÿä¸€é»‘å­—å¯è¯»æ€§æ›´å¥½
                    ha='center', va='center', fontweight='bold',
                    zorder=10, clip_on=False, path_effects=[pe.withStroke(linewidth=2.0, foreground='white')])  # ç™½æè¾¹
        texts.append(txt)  # æ”¶é›†
        return texts
    else:
        # draw line
        ax.plot(points[:, 0], points[:, 1], color=color, alpha=1.0, linewidth=2, zorder=2, label=label)
        # draw start and end vertex
        ax.scatter(points[[0, -1], 0], points[[0, -1], 1], color=color, s=10, zorder=2)
        # draw arrow

        ax.annotate('', xy=(points[-1, 0], points[-1, 1]),
                    xytext=(points[-2, 0], points[-2, 1]),
                    arrowprops=dict(arrowstyle='->', lw=2.0, color=color), zorder=2)
        return None

def _draw_lane_segment_alig_coord(ax, lane_segment, with_centerline, with_laneline, iid=None, all_num=None, multi_color_centerline = False, multi_color_laneline=False):
    texts = None

    if with_centerline:
        texts = _draw_centerline_align_coord(ax, {'points': lane_segment['centerline']}, label='Centerline', iid= iid, all_num=all_num, multi_color_centerline= multi_color_centerline)
 
    if with_laneline:
        line_type = {0:'Invisible boundary line', 1:'Solid boundary line', 2:'Dashed boundary line'}
        if multi_color_laneline:
            texts = []
            lane_name=f"{iid}"
            cmap = plt.get_cmap('tab20') 
            color = cmap(iid / max(1, all_num-1))

            _draw_line_align_coord(ax, {'points': lane_segment['left_laneline'], 'linetype': lane_segment['left_laneline_type']}, label = line_type[lane_segment['left_laneline_type']], multi_color_laneline = multi_color_laneline, color = color)
            _draw_line_align_coord(ax, {'points': lane_segment['right_laneline'], 'linetype': lane_segment['right_laneline_type']}, label = line_type[lane_segment['right_laneline_type']], multi_color_laneline = multi_color_laneline, color = color)
            
            left_pts = np.asarray(lane_segment['left_laneline'])
   
            right_pts = np.asarray(lane_segment['right_laneline'])

            middle_pts = (left_pts+right_pts)/2 
        
            mid = len(middle_pts)//2
            x, y = middle_pts[mid,0], middle_pts[mid,1]
            t = middle_pts[min(mid+1,len(middle_pts)-1)] - middle_pts[max(mid-1,0)]
            nx, ny = -t[0], t[1]
            nrm = np.hypot(nx,ny)+1e-6
            # x += 2.0*nx/nrm; y += 2.0*ny/nrm          # æ³•å‘åç§» 2 ä¸ªå•ä½
            x += np.random.uniform(5,5)          # è½»å¾®éšæœºåˆå§‹åŒ–
            y += np.random.uniform(5,5)

            txt = ax.text(x, y, lane_name,
                        fontsize=8, color=color,  # ç»Ÿä¸€é»‘å­—å¯è¯»æ€§æ›´å¥½
                        ha='center', va='center', fontweight='bold',
                        zorder=10, clip_on=False, path_effects=[pe.withStroke(linewidth=2.0, foreground='white')])  # ç™½æè¾¹
            texts.append(txt)  # æ”¶é›†

        else:
            _draw_line_align_coord(ax, {'points': lane_segment['left_laneline'], 'linetype': lane_segment['left_laneline_type']}, label = line_type[lane_segment['left_laneline_type']], multi_color_laneline = multi_color_laneline)
            _draw_line_align_coord(ax, {'points': lane_segment['right_laneline'], 'linetype': lane_segment['right_laneline_type']}, label = line_type[lane_segment['right_laneline_type']], multi_color_laneline = multi_color_laneline)
    return texts

def _draw_area_align_coord(ax, area, point_like=False, multi_color_area=False, iid=None, all_num=None):
    texts = None
    if point_like == True:
        if area['category'] == 1:  # ped crossing with lane segment style.

            if multi_color_area:
                texts = []
                lane_name=f"<PED{iid}>"
                cmap = plt.get_cmap('tab20') 
                color = cmap(iid / max(1, all_num-1))
                _draw_line_align_coord(ax, {'points': area['points'][0], 'linetype': 'ped_crossing'}, label='Pedestrian crossing', multi_color_laneline = multi_color_area, color = color)
                # color = COLOR_DICT['ped_crossing']
                points =  np.asarray(area['points'][0])

                ax.scatter(points[[0, -1], 0], points[[0, -1], 1], color=color, s=6, zorder=2)

                mid = len(points)//2
                x, y = points[mid,0], points[mid,1]
                t = points[min(mid+1,len(points)-1)] - points[max(mid-1,0)]
                nx, ny = -t[0], t[1]
                nrm = np.hypot(nx,ny)+1e-6
                # x += 2.0*nx/nrm; y += 2.0*ny/nrm          # æ³•å‘åç§» 2 ä¸ªå•ä½
                x += np.random.uniform(-0.5,0.5)          # è½»å¾®éšæœºåˆå§‹åŒ–
                y += np.random.uniform(-0.5,0.5)

                txt = ax.text(x, y, lane_name,
                            fontsize=12, color=color,  # ç»Ÿä¸€é»‘å­—å¯è¯»æ€§æ›´å¥½
                            ha='center', va='center', fontweight='bold',
                            zorder=10, clip_on=False, path_effects=[pe.withStroke(linewidth=2.0, foreground='white')])  # ç™½æè¾¹
                texts.append(txt)  # æ”¶é›†

            else:
                _draw_line_align_coord(ax, {'points': area['points'][0], 'linetype': 'ped_crossing'}, label='Pedestrian crossing')
                color = COLOR_DICT['ped_crossing']
                points = np.asarray(area['points'][0])
 
                ax.scatter(points[[0, -1], 0], points[[0, -1], 1], color=color, s=1, zorder=2)

    else:
        if area['category'] == 1:  # ped crossing with lane segment style.
            _draw_line_align_coord(ax, {'points': area['points'][0], 'linetype': 'ped_crossing'})

    return texts

def draw_annotation_bev_align_coord(annotation, with_centerline=True, with_laneline=True, with_area=True, with_car=False, point_like=False, with_nav=False, multi_color_centerline = False, multi_color_laneline = False, multi_color_area = False, rexy=False):

    fig, ax = plt.figure(figsize=(5, 10), dpi=100), plt.gca()
    ax.set_aspect('equal')
    ax.set_ylim([0, 1000])
    ax.set_xlim([0, 500])

    ax.invert_yaxis()
    ax.grid(False)
    ax.axis('off')
    ax.set_facecolor('white')
    fig.subplots_adjust(left=0, right=1, top=1, bottom=0)

    for iid, lane_segment in enumerate(annotation['lane_segment']):

        texts = _draw_lane_segment_alig_coord(ax, lane_segment, with_centerline, with_laneline, iid, len(annotation['lane_segment']), multi_color_centerline, multi_color_laneline)
        objects = []
    for line in ax.lines:
        objects.append(line)
    for coll in ax.collections:
        objects.append(coll)

    if multi_color_centerline:
    
        adjust_text(
        texts, ax=ax,
        only_move={'text': 'xy'},        # å…è®¸æ–‡æœ¬åœ¨ x/y ä¸¤æ–¹å‘ç§»åŠ¨
        expand_text=(1.8, 1.8),         # æ–‡æœ¬-æ–‡æœ¬æœ€å°é—´è·æ”¾å¤§
        expand_points=(1.4, 1.4),       # è‹¥æœ‰æ•£ç‚¹ä¹Ÿèƒ½é¿
        expand_objects=(1.4, 1.4),      # æ–‡æœ¬-çº¿/é¢ é—´è·æ”¾å¤§
        force_text=(2.5, 2.5),          # æ¨å¼€åŠ›åº¦æ›´å¤§
        force_points=(0.8, 0.8),
        force_objects=(1.0, 1.0),
        lim=1000,   
        precision=0.001, 
        add_objects=objects,           
        arrowprops=dict(arrowstyle='-', lw=0.5, color='0.3')  # éœ€è¦æ—¶ç»™æŒªè¿œçš„æ ‡ç­¾æ‹‰ç»†çº¿
        )
        
    if with_area:
        for iid, area in enumerate(annotation['area']):
  
            texts = _draw_area_align_coord(ax, area, point_like, multi_color_area, iid, len(annotation['lane_segment']))
        
        objects = []
        for line in ax.lines:
            objects.append(line)
        for coll in ax.collections:
            objects.append(coll)

        if multi_color_area:
            adjust_text(
            texts, ax=ax,
            only_move={'text': 'xy'},        # å…è®¸æ–‡æœ¬åœ¨ x/y ä¸¤æ–¹å‘ç§»åŠ¨
            expand_text=(2.0, 2.0),          # æ–‡æœ¬é—´æœ€å°é—´éš”æ”¾å¤§ç³»æ•°
            force_text=(1.0, 1.0), # æ¨å¼€åŠ›åº¦ï¼ˆè¶Šå¤§è¶Šåˆ†æ•£ï¼Œè¿­ä»£æ›´æ…¢ï¼‰
            lim=500,   
            precision=0.01, 
            add_objects=objects,           
            arrowprops=dict(arrowstyle='-', lw=0.5, color='0.3')  # éœ€è¦æ—¶ç»™æŒªè¿œçš„æ ‡ç­¾æ‹‰ç»†çº¿
            )

    if with_car:
        fig.patch.set_alpha(0.0)
        ax.set_facecolor("none")
        # ç»˜åˆ¶çº¢è‰²è¾¹æ¡†çš„çŸ©å½¢ï¼ˆæ‚¨å›¾ç‰‡ä¸­çš„ä¸»è¦å›¾æ¡ˆï¼‰
        # å®šä¹‰çŸ©å½¢å‚æ•°

        rect_width = 20   # çŸ©å½¢å®½åº¦
        rect_height = 40  # çŸ©å½¢é«˜åº¦
        line_length = 20 # é¡¶éƒ¨ç«–çº¿é•¿åº¦
        
        # è®¡ç®—çŸ©å½¢å·¦ä¸‹è§’åæ ‡ï¼ˆä½¿å…¶å±…ä¸­ï¼‰
        rect_x =  250-rect_width / 2
        rect_y = 500-rect_height / 2
        
        # ç»˜åˆ¶çº¢è‰²è¾¹æ¡†çŸ©å½¢ï¼ˆé€æ˜å¡«å……ï¼‰
        rect = plt.Rectangle(
            (rect_x, rect_y), 
            rect_width, 
            rect_height,
            linewidth=2,        # è¾¹æ¡†çº¿å®½
            edgecolor='red',      # çº¢è‰²è¾¹æ¡†
            facecolor='none',
            zorder=3, label = 'Ego vehicle'     # é€æ˜å¡«å……

        )
       
        ax.add_patch(rect)

    fig.canvas.draw()  # å…³é”®ï¼šæ¸²æŸ“ä¸€æ¬¡ï¼Œæ‰èƒ½è·å– legend çš„ä½ç½®

    data = np.frombuffer(fig.canvas.tostring_rgb(), dtype=np.uint8)
    data = data.reshape(fig.canvas.get_width_height()[::-1] + (3,))
    plt.close(fig)
    return data

def render_lane_and_ped(annotation, with_car=True):
    """
    å¯¹ä¸€ä¸ª annotation ç”Ÿæˆä¸¤å¼ å›¾ï¼š
    1. åªç”» laneï¼ˆcenterlineï¼‰
    2. åªç”» ped crossingï¼ˆarea, category == 1ï¼‰
    è¿”å› (lane_img, ped_img)ï¼Œéƒ½æ˜¯ BGR æ ¼å¼
    """

    # Lane å›¾
    lane_img = draw_annotation_bev_align_coord(
        annotation,
        with_centerline=True,      # ç”» centerline
        with_laneline=False,       # å¦‚æœä½ ä¹Ÿæƒ³çœ‹å·¦å³è½¦é“çº¿ï¼Œå¯æ”¹ True
        with_area=False,
        with_car=with_car,
        point_like=False,
        with_nav=True,
        multi_color_centerline=True,
        multi_color_laneline=False,
        multi_color_area=False,
    )[..., ::-1]  # RGB -> BGRï¼Œæ–¹ä¾¿ç”¨ mmcv / cv2 ä¿å­˜

    # Ped å›¾
    ped_img = draw_annotation_bev_align_coord(
        annotation,
        with_centerline=False,
        with_laneline=False,
        with_area=True,            # åªç”» area é‡Œçš„è¡Œäººæ¨ªé“
        with_car=with_car,
        point_like=True,           # ä½ åŸæ¥ ped_cross æ˜¯ point_like=True çš„é‚£ç§ç”»æ³•
        with_nav=True,
        multi_color_centerline=False,
        multi_color_laneline=False,
        multi_color_area=True,
    )[..., ::-1]

    return lane_img, ped_img

def put_label(img, text):
    """
    åœ¨å›¾å·¦ä¸Šè§’å†™ä¸€ä¸ªæ–‡æœ¬æ ‡ç­¾ï¼Œæ¯”å¦‚ 'GT-Lane' / 'Pred-Ped'
    """
    img = img.copy()
    cv2.putText(
        img,
        text,
        (10, 30),
        cv2.FONT_HERSHEY_SIMPLEX,
        0.8,
        (0, 0, 0),
        2,
        cv2.LINE_AA,
    )
    return img

def visualize_one_result_entry(result_entry,
                               out_dir,
                               segment_id="seg",
                               timestamp="ts"):
    """
    result_entry: eval_results['detailed_results']['predictions'][k]['result']
        é‡Œé¢åŒ…å« prediction / ground_truth ä¸¤ä¸ªå­—æ®µ

    out_dir: è¾“å‡ºæ ¹ç›®å½•
    """

    pred_obj = result_entry.get("prediction", {})
    gt_obj = result_entry.get("ground_truth", {})

    # 1âƒ£ï¸ å– lanes å¹¶è½¬æˆ annotation æ ¼å¼
    pred_lanes = pred_obj.get("lanes", [])
    gt_lanes = gt_obj.get("lanes", [])

    pred_annotation = lanes_to_annotation(pred_lanes)
    gt_annotation = lanes_to_annotation(gt_lanes)

    # 2âƒ£ï¸ åˆ†åˆ«ç”» GT / Pred çš„ lane å’Œ ped
    gt_lane_img, gt_ped_img = render_lane_and_ped(gt_annotation, with_car=True)
    pred_lane_img, pred_ped_img = render_lane_and_ped(pred_annotation, with_car=True)

    # 3âƒ£ï¸ åŠ æ ‡ç­¾æ–¹ä¾¿è‚‰çœ¼çœ‹
    gt_lane_labeled = put_label(gt_lane_img, "GT-Lane")
    pred_lane_labeled = put_label(pred_lane_img, "Pred-Lane")
    gt_ped_labeled = put_label(gt_ped_img, "GT-Ped")
    pred_ped_labeled = put_label(pred_ped_img, "Pred-Ped")

    # 4âƒ£ï¸ ä¿è¯å°ºå¯¸ä¸€è‡´ï¼ˆdraw_annotation_bev_align_coord å‚æ•°ä¸€æ ·æ—¶ï¼Œç†è®ºä¸Šå°ºå¯¸ä¸€è‡´ï¼‰
    # å¦‚æœä½ åé¢æ”¹äº† figsize/dpi ä¸åŒï¼Œå¯ä»¥åœ¨è¿™é‡Œç»Ÿä¸€ resize
    h, w = gt_lane_labeled.shape[:2]
    def _ensure_size(img):
        if img.shape[0] != h or img.shape[1] != w:
            return cv2.resize(img, (w, h))
        return img

    pred_lane_labeled = _ensure_size(pred_lane_labeled)
    gt_ped_labeled = _ensure_size(gt_ped_labeled)
    pred_ped_labeled = _ensure_size(pred_ped_labeled)

    # 5âƒ£ï¸ 2Ã—2 æ‹¼å›¾ï¼š
    # [ GT-Lane   |  Pred-Lane ]
    # [ GT-Ped    |  Pred-Ped  ]
    row_lane = np.concatenate([gt_lane_labeled, pred_lane_labeled], axis=1)
    row_ped = np.concatenate([gt_ped_labeled,  pred_ped_labeled],  axis=1)
    grid = np.concatenate([row_lane, row_ped], axis=0)

    # 6âƒ£ï¸ ä¿å­˜
    save_dir = os.path.join(out_dir, str(segment_id))
    os.makedirs(save_dir, exist_ok=True)
    save_path = os.path.join(save_dir, str(timestamp)+"_lane_ped_gt_pred_grid.jpg")
    mmcv.imwrite(grid, save_path)
    print(f"âœ… Saved GT/Pred lane+ped comparison to: {save_path}")

def visualize_all_results(eval_json_path, out_dir):
    """
    æ‰¹é‡å¯è§†åŒ– eval_results.json é‡Œçš„æ‰€æœ‰æ¡ç›®ã€‚
    æ¯ä¸ª sample è¾“å‡ºå››å¼ æ‹¼æˆçš„ 2Ã—2 å›¾:
        [ GT-Lane | Pred-Lane ]
        [ GT-Ped  | Pred-Ped  ]

    å¹¶ä¸”å¯¹æ¯ä¸ª scene(segment_id) ä¸‹é¢çš„æ‰€æœ‰ timestamp å¸§ï¼ŒæŒ‰æ—¶é—´é¡ºåºä¿å­˜æˆä¸€ä¸ª gifã€‚
    """

    print(f"ğŸ“‚ Loading eval results from: {eval_json_path}")
    with open(eval_json_path, "r", encoding="utf-8") as f:
        data = json.load(f)

    predictions = data["detailed_results"]["predictions"]
    print(f"ğŸ”¢ Found {len(predictions)} samples to visualize.")

    # ç”¨æ¥è®°å½•ï¼šæ¯ä¸ª scene ä¸‹æœ‰å“ªäº›å¸§ï¼ˆtimestamp, jpg_pathï¼‰
    scene_frames = {}

    for item in predictions:
        idx = item.get("sample_idx")
        segment_id = item.get("segment_id", f"sample_{idx}")
        timestamp = item.get("timestamp", "0")
        result_entry = item.get("result", {})

        if not result_entry:
            print(f"âš ï¸ Sample {idx} has empty result, skip.")
            continue

        pred_obj = result_entry.get("prediction", {})
        gt_obj = result_entry.get("ground_truth", {})

        if not pred_obj or not gt_obj:
            print(f"âš ï¸ Sample {idx}: missing pred/gt, skip.")
            continue

        # --- Convert lanes â†’ annotation format ---
        pred_annotation = lanes_to_annotation(pred_obj.get("lanes", []))
        gt_annotation = lanes_to_annotation(gt_obj.get("lanes", []))

        # --- Render lane + ped ---
        gt_lane_img, gt_ped_img = render_lane_and_ped(gt_annotation)
        pred_lane_img, pred_ped_img = render_lane_and_ped(pred_annotation)

        # --- Add labels ---
        gt_lane_img = put_label(gt_lane_img, f"GT-Lane ({idx})")
        pred_lane_img = put_label(pred_lane_img, f"Pred-Lane ({idx})")
        gt_ped_img = put_label(gt_ped_img, f"GT-Ped ({idx})")
        pred_ped_img = put_label(pred_ped_img, f"Pred-Ped ({idx})")

        # --- Ensure same size ---
        h, w = gt_lane_img.shape[:2]
        def _resize(img):
            return cv2.resize(img, (w, h)) if img.shape[:2] != (h, w) else img

        pred_lane_img = _resize(pred_lane_img)
        gt_ped_img = _resize(gt_ped_img)
        pred_ped_img = _resize(pred_ped_img)

        # --- Stitch into 2Ã—2 grid ---
        row1 = np.concatenate([gt_lane_img, pred_lane_img], axis=1)
        row2 = np.concatenate([gt_ped_img, pred_ped_img], axis=1)
        grid = np.concatenate([row1, row2], axis=0)

        # --- Save single frame jpg ---
        save_dir = os.path.join(out_dir, str(segment_id))
        os.makedirs(save_dir, exist_ok=True)
        frame_name = str(timestamp) + "_lane_ped_gt_pred_grid.jpg"
        save_path = os.path.join(save_dir, frame_name)

        mmcv.imwrite(grid, save_path)
        print(f"âœ… Saved sample {idx} â†’ {save_path}")

        # --- è®°å½•åˆ°å¯¹åº” scene çš„å¸§åˆ—è¡¨é‡Œ ---
        scene_frames.setdefault(segment_id, []).append((timestamp, save_path))

    print("ğŸ“¸ All JPG frames saved, now making GIFs per scene...")

    # --- ä¸ºæ¯ä¸ª scene ç”Ÿæˆ gif ---
    for scene_id, frames in scene_frames.items():
        # æŒ‰ timestamp æ’åºï¼ˆå°½é‡æŒ‰æ—¶é—´é¡ºåºæ’­æ”¾ï¼‰
        def _ts_key(t):
            ts = str(t[0])
            try:
                return int(ts)
            except ValueError:
                return ts  # å¦‚æœä¸æ˜¯çº¯æ•°å­—ï¼Œå°±æŒ‰å­—ç¬¦ä¸²æ’åº

        frames_sorted = sorted(frames, key=_ts_key)

        images = []
        for ts, path in frames_sorted:
            img = imageio.imread(path)
            images.append(img)

        if not images:
            print(f"âš ï¸ Scene {scene_id} has no images, skip GIF.")
            continue

        gif_path = os.path.join(out_dir, str(scene_id), f"{scene_id}_lane_ped_gt_pred.gif")

        # ğŸ”¸ æ§åˆ¶é€Ÿåº¦çš„ä¸¤ä¸ªå‚æ•°ï¼š
        ORI_FRAME_DURATION = 0.5   # æ¯ä¸ªâ€œå­å¸§â€çš„æ—¶é—´ï¼ˆç§’ï¼‰
        REPEAT_PER_FRAME = 2       # æ¯ä¸€å¼ åŸå›¾é‡å¤å¤šå°‘æ¬¡

        # 1) å±•å¼€å¸§ï¼šæ¯”å¦‚ 10 å¼  â†’ 10 * 4 = 40 å¸§
        expanded_frames = []
        durations = []
        for img in images:
            for _ in range(REPEAT_PER_FRAME):
                expanded_frames.append(img)
                durations.append(ORI_FRAME_DURATION)

        # 2) ä¿å­˜ gif
        imageio.mimsave(
            gif_path,
            expanded_frames,
            duration=durations,   # å¯ä»¥æ˜¯ listï¼Œå’Œå¸§æ•°ä¸€æ ·é•¿
            loop=0,               # 0 = æ— é™å¾ªç¯
        )
        print(f"ğŸ Saved GIF for scene {scene_id}: {gif_path}")

    print("ğŸ‰ All samples visualized & GIFs generated!")

def test_all_results(eval_json_path, out_dir, use_select_scenes=False, select_scenes=None):
    """
    æ‰¹é‡å¯è§†åŒ– eval_results.json é‡Œçš„æ‰€æœ‰æ¡ç›®ã€‚
    æ¯ä¸ª sample è¾“å‡ºå››å¼ æ‹¼æˆçš„ 2Ã—2 å›¾:
        [ GT-Lane | Pred-Lane ]
        [ GT-Ped  | Pred-Ped  ]

    å¹¶ä¸”å¯¹æ¯ä¸ª scene(segment_id) ä¸‹é¢çš„æ‰€æœ‰ timestamp å¸§ï¼ŒæŒ‰æ—¶é—´é¡ºåºä¿å­˜æˆä¸€ä¸ª gifã€‚
    
    Args:
        eval_json_path: è¯„ä¼°ç»“æœJSONæ–‡ä»¶è·¯å¾„
        out_dir: è¾“å‡ºç›®å½•
        use_select_scenes: æ˜¯å¦åªè®¡ç®—selectåœºæ™¯çš„æŒ‡æ ‡
        select_scenes: è¦è®¡ç®—çš„åœºæ™¯IDåˆ—è¡¨ï¼ˆå½“use_select_scenes=Trueæ—¶ç”Ÿæ•ˆï¼‰
    """

    with open(eval_json_path, "r", encoding="utf-8") as f:
        data = json.load(f)

    predictions = data["detailed_results"]["predictions"]
    print(f"ğŸ”¢ Found {len(predictions)} samples to evaluate.")

    # ç”¨æ¥è®°å½•ï¼šæ¯ä¸ª scene ä¸‹æœ‰å“ªäº›å¸§ï¼ˆtimestamp, jpg_pathï¼‰
    scene_frames = {}

    data_infos = load_annotations('/data_test/home/lizhen/yym/TopoWMChange/data/data_dict_subset_A_val_lanesegnet.pkl')
    
    # æ ¹æ®flagå†³å®šæ˜¯å¦è¿‡æ»¤åœºæ™¯
    scenes_to_use = select_scenes if use_select_scenes else None
    if use_select_scenes and select_scenes:
        print(f"ğŸ¯ åªè®¡ç®—ä»¥ä¸‹ {len(select_scenes)} ä¸ªåœºæ™¯çš„æŒ‡æ ‡: {select_scenes}")
    else:
        print(f"ğŸŒ è®¡ç®—æ‰€æœ‰åœºæ™¯çš„æŒ‡æ ‡")
    
    gt_dict = format_openlanev2_gt(data_infos, select_scenes=scenes_to_use)
    pred_dict = format_results(data, data_infos, select_scenes=scenes_to_use)
    # gt_dict = mmcv.load("./formated_results/gt_results.pkl", file_format="pkl")
    # out_dir = "./formated_results"
    # if out_dir is not None:
    #     if not os.path.exists(out_dir):
    #         os.makedirs(out_dir)
    #     mmcv.dump(pred_dict, os.path.join(out_dir, 'pred_results.pkl'))
    #     mmcv.dump(gt_dict, os.path.join(out_dir, 'gt_results.pkl'))
    metric_results = lanesegnet_evaluate(gt_dict, pred_dict)
    
    # è®¡ç®—selectåœºæ™¯çš„å¹³å‡æŒ‡æ ‡
    if use_select_scenes and select_scenes and 'per_scene' in metric_results:
        select_scenes_set = set(str(s) for s in select_scenes)
        scene_metrics_list = []
        
        for scene_id, scene_metrics in metric_results['per_scene'].items():
            if scene_id in select_scenes_set:
                scene_metrics_list.append(scene_metrics)
        
        if scene_metrics_list:
            avg_f1_ls = np.mean([m['F1_ls'] for m in scene_metrics_list])
            avg_f1_ped = np.mean([m['F1_ped'] for m in scene_metrics_list])
            avg_top_lsls = np.mean([m['TOP_lsls'] for m in scene_metrics_list])
            avg_mf1 = (avg_f1_ls + avg_f1_ped) / 2
            total_frames = sum([m['num_frames'] for m in scene_metrics_list])
            
            print(f"\n{'='*60}")
            print(f"ğŸ“Š Selectåœºæ™¯å¹³å‡æŒ‡æ ‡ ({len(scene_metrics_list)} ä¸ªåœºæ™¯, {total_frames} å¸§):")
            print(f"{'='*60}")
            print(f"   F1_ls (è½¦é“çº¿):     {avg_f1_ls:.4f}")
            print(f"   F1_ped (è¡Œäººæ¨ªé“):  {avg_f1_ped:.4f}")
            print(f"   TOP_lsls (æ‹“æ‰‘):    {avg_top_lsls:.4f}")
            print(f"   mF1 (å¹³å‡):         {avg_mf1:.4f}")
            print(f"{'='*60}")
            
            # ä¿å­˜å¹³å‡æŒ‡æ ‡åˆ°metric_resultsä¸­
            metric_results['select_scenes_avg'] = {
                'F1_ls': float(avg_f1_ls),
                'F1_ped': float(avg_f1_ped),
                'TOP_lsls': float(avg_top_lsls),
                'mF1': float(avg_mf1),
                'num_scenes': len(scene_metrics_list),
                'num_frames': total_frames,
                'scene_ids': select_scenes
            }
    
    return metric_results

def format_results( results, data_infos, jsonfile_prefix=None, select_scenes=None):
    pred_dict = {}
    pred_dict['method'] = 'TopoCoT'
    pred_dict['authors'] = []
    pred_dict['e-mail'] = 'dummy'
    pred_dict['institution / company'] = 'CUHKSZ'
    pred_dict['country / region'] = 'CN'
    pred_dict['results'] = {}

    # ç»Ÿè®¡ä¿¡æ¯
    stats = {
        'total_samples': 0,
        'error_marked': 0,           # answer_json_str == "error"
        'json_parse_failed': 0,      # JSON è§£æå¤±è´¥
        'not_dict': 0,               # ä¸æ˜¯å­—å…¸ç±»å‹
        'missing_lanes': 0,          # ç¼ºå°‘ 'lanes' é”®
        'missing_topology': 0,       # ç¼ºå°‘ 'topology' é”®
        'success': 0,                # æˆåŠŸå¤„ç†
        'filtered_by_scene': 0       # è¢«åœºæ™¯è¿‡æ»¤æ‰çš„æ ·æœ¬
    }
    
    # å¦‚æœæŒ‡å®šäº†select_scenesï¼Œè½¬æ¢ä¸ºsetä»¥ä¾¿å¿«é€ŸæŸ¥æ‰¾
    select_scenes_set = set(select_scenes) if select_scenes else None
    
    for idx, result in enumerate(results['detailed_results']['predictions']):
        stats['total_samples'] += 1
        info = data_infos[idx]
        
        # åœºæ™¯è¿‡æ»¤ï¼šå¦‚æœæŒ‡å®šäº†select_scenesï¼Œåªå¤„ç†è¿™äº›åœºæ™¯
        if select_scenes_set is not None:
            if str(info['segment_id']) not in select_scenes_set:
                stats['filtered_by_scene'] += 1
                continue
        
        key = (split, info['segment_id'], str(info['timestamp']))

        pred_info = dict(
            lane_segment = [],
            area = [],
            traffic_element = [],
            topology_lsls = None,
            topology_lste = None
        )

        lane_results = None
        lanes = []
        lane_ids = []
        
        if result['result']['answer_json_str'] is not None:
            lane_results = result['result']['answer_json_str']
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯é”™è¯¯æ ‡è®°
            if lane_results == "error":
                stats['error_marked'] += 1
                # print(f"[WARN] Sample {idx}: answer_json_str is 'error', skip.")
                continue
            
            try:
                lane_results = json.loads(lane_results)
            except json.JSONDecodeError as e:
                # ğŸ‘‰ æ•´ä¸ª scene ä½œåºŸ
                stats['json_parse_failed'] += 1
                # print(f"[WARN] JSON parse failed at sample {idx}: {e}")
                # pred_dict['results'][key] = dict(predictions=pred_info)

                continue
            
            # æ£€æŸ¥å¿…éœ€çš„å±æ€§ï¼šlanes å’Œ topology
            if not isinstance(lane_results, dict):
                stats['not_dict'] += 1
                # print(f"[WARN] Sample {idx}: lane_results is not a dict, skip.")
                continue
            
            if 'lanes' not in lane_results:
                stats['missing_lanes'] += 1
                # print(f"[WARN] Sample {idx}: lane_results missing 'lanes' key, skip.", lane_results.keys())
                continue
            
            if 'topology' not in lane_results:
                stats['missing_topology'] += 1
                # print(f"[WARN] Sample {idx}: lane_results missing 'topology' key, skip.", lane_results.keys())
                continue

            lanes = []
            labels = []

            lane_ids = []
           
            for lane_single in lane_results['lanes']:
                # æ¸…ç†å’ŒéªŒè¯ç‚¹æ•°æ®
                cleaned_points = clean_and_validate_points(lane_single.get('point', []))
                
                # å¦‚æœç‚¹æ•°æ®æ— æ•ˆï¼Œè·³è¿‡è¿™æ¡è½¦é“çº¿
                if cleaned_points is None or len(cleaned_points) == 0:
                    lane_id = lane_single.get('id', 'unknown')
                    print(f"âš ï¸ Sample {idx}: lane {lane_id} has invalid points, skip.")
                    continue
                
                lanes.append(cleaned_points)
                
                # æ ¹æ® id åˆ¤æ–­æ˜¯ LANE è¿˜æ˜¯ PED
                lane_id = lane_single.get('id', lane_single.get(' id', ''))
                if isinstance(lane_id, str):
                    if lane_id.startswith('LANE'):
                        labels.append(0)
                    elif lane_id.startswith('PED'):
                        labels.append(1)
                    else:
                        print(f"âš ï¸ Sample {idx}: unknown lane id format: {lane_id}")
                        labels.append(0)
                else:
                    # å¦‚æœ id ä¸æ˜¯å­—ç¬¦ä¸²ï¼Œé»˜è®¤å½“ä½œ centerline
                    labels.append(0)

                lane_ids.append(lane_single.get('id', lane_single.get(' id', f'lane_{len(lane_ids)}')))
            # æ£€æŸ¥æ˜¯å¦æœ‰æœ‰æ•ˆçš„è½¦é“çº¿
            if len(lanes) == 0:
                print(f"âš ï¸ Sample {idx}: no valid lanes after cleaning, skip.")
                continue
            
            # lanes ä¿æŒä¸ºåˆ—è¡¨ï¼Œå› ä¸ºæ¯ä¸ªè½¦é“çº¿çš„ç‚¹æ•°å¯èƒ½ä¸åŒ
            labels = np.array(labels, dtype=np.int64 )

            pred_area_index = []
            for pred_idx, (lane, label) in enumerate(zip(lanes, labels)):
                if label == 0:
                    # lane å·²ç»æ˜¯æ¸…ç†åçš„ numpy æ•°ç»„
                    points = np.asarray(lane, dtype=np.float32)
                    
                    # å†æ¬¡éªŒè¯ç‚¹çš„æœ‰æ•ˆæ€§
                    if len(points) == 0 or points.shape[1] != 2:
                        print(f"âš ï¸ Sample {idx}: lane {pred_idx} has invalid points after cleaning, skip.")
                        continue

                    pred_lane_segment = {}
                    pred_lane_segment['id'] = 20000 + pred_idx
                    pred_lane_segment['centerline'] = opencv_to_bev(fix_pts_interpolate(points, 10))
                    left_lane, right_lane = pred_lane_segment['centerline'], pred_lane_segment['centerline']
                    pred_lane_segment['left_laneline'] = left_lane
                    pred_lane_segment['right_laneline'] = right_lane

                    pred_lane_segment['confidence'] = 1.0
                    pred_info['lane_segment'].append(pred_lane_segment)
                    
                elif label == 1:
                    # lane å·²ç»æ˜¯æ¸…ç†åçš„ numpy æ•°ç»„
                    points = np.asarray(lane, dtype=np.float32)
                    
                    # å†æ¬¡éªŒè¯ç‚¹çš„æœ‰æ•ˆæ€§
                    if len(points) == 0 or points.shape[1] != 2:
                        print(f"âš ï¸ Sample {idx}: ped {pred_idx} has invalid points after cleaning, skip.")
                        continue
                    
                    pred_ped = {}
                    pred_ped['id'] = 20000 + pred_idx
                    pred_points = opencv_to_bev(fix_pts_interpolate(points, 10))

                    pred_ped['points'] = pred_points
                    pred_ped['category'] = label
                    pred_ped['confidence'] = 1.0
                    pred_info['area'].append(pred_ped)
                    pred_area_index.append(pred_idx)
 
                elif label == 2:
                    raise NotImplementedError

            # å¤„ç†topologyï¼ˆåœ¨ifå—å†…ï¼‰
            if lane_results is not None and lane_results.get('topology') is not None:
                topology = lane_results['topology']

                lane2idx = {lane: i for i, lane in enumerate(lane_ids)}
                idx2lane = {i: lane for lane, i in lane2idx.items()}
                N = len(lanes)
                adj = np.zeros((N, N), dtype=np.float32)

                for path in topology:
                    for u, v in zip(path[:-1], path[1:]):
                        try:
                            adj[lane2idx[u], lane2idx[v]] = 1.0
                        except:
                            pass
                
                pred_info['topology_lsls'] = adj
            else:
                N = len(lanes) if lanes else 0
                adj = np.zeros((N, N), dtype=np.float32)
                pred_info['topology_lsls'] = adj

        pred_dict['results'][key] = dict(predictions=pred_info)
        stats['success'] += 1

    # è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
    print(f"\nğŸ“Š ç»“æœè¯»å–ç»Ÿè®¡:")
    print(f"   æ€»æ ·æœ¬æ•°: {stats['total_samples']}")
    if select_scenes_set is not None:
        print(f"   åœºæ™¯è¿‡æ»¤: {stats['filtered_by_scene']} ä¸ªæ ·æœ¬è¢«è¿‡æ»¤ï¼ˆä¸åœ¨select_scenesåˆ—è¡¨ä¸­ï¼‰")
    print(f"   æˆåŠŸå¤„ç†: {stats['success']} ä¸ª")
    print(f"   æ— æ³•è¯»å–: {stats['total_samples'] - stats['success'] - stats['filtered_by_scene']} ä¸ª")
    print(f"      - é”™è¯¯æ ‡è®° (error): {stats['error_marked']} ä¸ª")
    print(f"      - JSON è§£æå¤±è´¥: {stats['json_parse_failed']} ä¸ª")
    print(f"      - ä¸æ˜¯å­—å…¸ç±»å‹: {stats['not_dict']} ä¸ª")
    print(f"      - ç¼ºå°‘ 'lanes' é”®: {stats['missing_lanes']} ä¸ª")
    print(f"      - ç¼ºå°‘ 'topology' é”®: {stats['missing_topology']} ä¸ª")
    valid_samples = stats['total_samples'] - stats['filtered_by_scene']
    print(f"   æˆåŠŸç‡: {stats['success']/max(1, valid_samples)*100:.2f}%")

    return pred_dict

def format_openlanev2_gt(data_infos, select_scenes=None):
    gt_dict = {}
    # å¦‚æœæŒ‡å®šäº†select_scenesï¼Œè½¬æ¢ä¸ºsetä»¥ä¾¿å¿«é€ŸæŸ¥æ‰¾
    select_scenes_set = set(select_scenes) if select_scenes else None
    
    for idx in range(len(data_infos)):
        info = copy.deepcopy(data_infos[idx])
        
        # åœºæ™¯è¿‡æ»¤ï¼šå¦‚æœæŒ‡å®šäº†select_scenesï¼Œåªå¤„ç†è¿™äº›åœºæ™¯
        if select_scenes_set is not None:
            if str(info['segment_id']) not in select_scenes_set:
                continue
        
        key = (split, info['segment_id'], str(info['timestamp']))
        areas = []
        for lane_segment in info['annotation']['lane_segment']:
            lane_segment['centerline'] = lane_segment['centerline'][:, :2]

        for area in info['annotation']['area']:
            if area['category'] == 1:
                points = area['points']
                # left_boundary = fix_pts_interpolate(points[[0, 1]], 10)
                # right_boundary = fix_pts_interpolate(points[[2, 3]], 10)
                # area['points'] = np.concatenate([left_boundary, right_boundary], axis=0)
                # import pdb; pdb.set_trace()
                assert points.shape[0] == 5
                dir_vector = points[1] - points[0]
                dir = np.rad2deg(np.arctan2(dir_vector[1], dir_vector[0]))

                if dir < -45 or dir > 135:
                    left_boundary = points[[2, 3]]
                    right_boundary = points[[1, 0]]
                else:
                    left_boundary = points[[0, 1]]
                    right_boundary = points[[3, 2]]
                left_boundary = fix_pts_interpolate(left_boundary, 10)
                right_boundary = fix_pts_interpolate(right_boundary, 10)
                centerline = (left_boundary + right_boundary)/2
                centerline = centerline[:,:2]
            
                area['points'] = centerline
                areas.append(area)
        info['annotation']['area'] = areas
        gt_dict[key] = info
     
    return gt_dict

def load_annotations(ann_file):
    """Load annotation from a olv2 pkl file.

    Args:
        ann_file (str): Path of the annotation file.

    Returns:
        list[dict]: Annotation info from the json file.
    """
    with open(ann_file, "rb") as f:
        data_infos = pickle.load(f)
    if isinstance(data_infos, dict):
        if  split == 'train':
            data_infos = [info for info in data_infos.values() if info['meta_data']['source_id'] not in MAP_CHANGE_LOGS]
        else:
            data_infos = list(data_infos.values())
    return data_infos

def fix_json_string(text):
    """
    å°è¯•ä¿®å¤ JSON å­—ç¬¦ä¸²ï¼Œå¤„ç†å¸¸è§çš„æ ¼å¼é”™è¯¯ï¼š
    - ç¬¬ä¸€ä¸ªå­—ç¬¦ç¼ºå°‘ {
    - æœ€åä¸€ä¸ªå­—ç¬¦ç¼ºå°‘ }
    - æ•´ä¸ª JSON è¢«åŒ…åœ¨å­—ç¬¦ä¸²ä¸­ï¼ˆä»¥ " å¼€å¤´å’Œç»“å°¾ï¼‰
    - å…¶ä»–æ‹¬å·ä¸åŒ¹é…çš„æƒ…å†µ
    """
    if not text or not isinstance(text, str):
        return text
    
    original_text = text  # ä¿å­˜åŸå§‹æ–‡æœ¬
    text = text.strip()
    if not text:
        return original_text
    
    # é¦–å…ˆå°è¯•ç›´æ¥è§£æ
    try:
        json.loads(text)
        return text
    except (json.JSONDecodeError, RecursionError):
        pass
    
    # æƒ…å†µ1: å¦‚æœä»¥ " å¼€å¤´ï¼Œå¯èƒ½æ˜¯æ•´ä¸ª JSON è¢«åŒ…åœ¨å­—ç¬¦ä¸²ä¸­
    if text.startswith('"'):
        # å¦‚æœä»¥ " å¼€å¤´å’Œç»“å°¾ï¼Œå°è¯•å»æ‰å¤–å±‚çš„å¼•å·
        if text.endswith('"'):
            unquoted = text[1:-1]
            try:
                json.loads(unquoted)
                return unquoted
            except (json.JSONDecodeError, RecursionError):
                pass
        
        # å¦‚æœä»¥ " å¼€å¤´ä½†ç¬¬äºŒä¸ªå­—ç¬¦æ˜¯ {ï¼Œå°è¯•å»æ‰ç¬¬ä¸€ä¸ªå¼•å·
        if len(text) > 1 and text[1] == '{':
            unquoted = text[1:]
            try:
                json.loads(unquoted)
                return unquoted
            except (json.JSONDecodeError, RecursionError):
                pass
        
        # å¦‚æœä»¥ " å¼€å¤´ä½†ç¬¬äºŒä¸ªå­—ç¬¦ä¸æ˜¯ {ï¼Œå°è¯•åœ¨å¼•å·å‰æ·»åŠ  {
        if len(text) > 1 and text[1] != '{':
            try:
                fixed = '{' + text
                json.loads(fixed)
                return fixed
            except (json.JSONDecodeError, RecursionError):
                pass
    
    # æƒ…å†µ3: æ£€æŸ¥ç¬¬ä¸€ä¸ªå­—ç¬¦
    if not text.startswith('{'):
        # å¦‚æœç¬¬ä¸€ä¸ªå­—ç¬¦ä¸æ˜¯ {ï¼Œå°è¯•æ·»åŠ 
        if text.startswith('"') or text.startswith('['):
            # å¦‚æœä»¥ " æˆ– [ å¼€å¤´ï¼Œå¯èƒ½éœ€è¦æ·»åŠ  {
            text = '{' + text
        elif text[0] in '([<':
            # å¦‚æœä»¥å…¶ä»–æ‹¬å·å¼€å¤´ï¼Œæ›¿æ¢ä¸º {
            text = '{' + text[1:]
        else:
            # å…¶ä»–æƒ…å†µï¼Œç›´æ¥æ·»åŠ  {
            text = '{' + text
    
    # æƒ…å†µ4: æ£€æŸ¥æœ€åä¸€ä¸ªå­—ç¬¦
    if not text.endswith('}'):
        # å¦‚æœæœ€åä¸€ä¸ªå­—ç¬¦ä¸æ˜¯ }ï¼Œå°è¯•æ·»åŠ 
        if text.endswith('"') or text.endswith(']'):
            # å¦‚æœä»¥ " æˆ– ] ç»“å°¾ï¼Œå¯èƒ½éœ€è¦æ·»åŠ  }
            text = text + '}'
        elif text[-1] in ')]>':
            # å¦‚æœä»¥å…¶ä»–æ‹¬å·ç»“å°¾ï¼Œæ›¿æ¢ä¸º }
            text = text[:-1] + '}'
        else:
            # å…¶ä»–æƒ…å†µï¼Œç›´æ¥æ·»åŠ  }
            text = text + '}'
    
    # å†æ¬¡å°è¯•è§£æï¼Œæ•è·æ‰€æœ‰å¯èƒ½çš„å¼‚å¸¸ï¼ˆåŒ…æ‹¬é€’å½’é”™è¯¯ï¼‰
    try:
        json.loads(text)
        return text
    except (json.JSONDecodeError, RecursionError, Exception):
        # å¦‚æœè¿˜æ˜¯å¤±è´¥ï¼ˆåŒ…æ‹¬é€’å½’é”™è¯¯ï¼‰ï¼Œè¿”å›åŸå§‹æ–‡æœ¬ï¼ˆè®©è°ƒç”¨è€…å¤„ç†ï¼‰
        return original_text

def collect_llm_results_from_test_output(test_output_dir):
    """
    ä» test_output ç›®å½•æ”¶é›†æ‰€æœ‰ llm_generated_text.txt æ–‡ä»¶ï¼Œæ±‡æ€»æˆ eval_result_examples.json æ ¼å¼ã€‚
    
    Args:
        test_output_dir (str): test_output ç›®å½•è·¯å¾„
        
    Returns:
        dict: æ ¼å¼ä¸ eval_result_examples.json ç›¸åŒçš„ç»“æœå­—å…¸
    """
    result = {
        "detailed_results": {
            "predictions": []
        }
    }
    
    predictions = []
    sample_idx = 1
    
    # éå† test_output ç›®å½•
    test_output_path = Path(test_output_dir)
    if not test_output_path.exists():
        print(f"âš ï¸ ç›®å½•ä¸å­˜åœ¨: {test_output_dir}")
        return result
    
    # æŸ¥æ‰¾æ‰€æœ‰ llm_generated_text.txt æ–‡ä»¶
    # è·¯å¾„æ ¼å¼: test_output/{segment_id}/{timestamp}/llm_generated_text.txt
    llm_files = list(test_output_path.glob("*/*/llm_generated_text.txt"))
    
    if not llm_files:
        print(f"âš ï¸ æœªæ‰¾åˆ°ä»»ä½• llm_generated_text.txt æ–‡ä»¶åœ¨: {test_output_dir}")
        return result
    
    print(f"ğŸ“‚ æ‰¾åˆ° {len(llm_files)} ä¸ª llm_generated_text.txt æ–‡ä»¶")
    
    # ç»Ÿè®¡ä¿¡æ¯
    stats = {
        "total_files": 0,
        "original_parse_success": 0,  # åŸå§‹ JSON è§£ææˆåŠŸ
        "fixed_parse_success": 0,     # ä¿®å¤åè§£ææˆåŠŸ
        "parse_failed": 0              # æœ€ç»ˆè§£æå¤±è´¥
    }
    
    for llm_file in sorted(llm_files):
        # ä»è·¯å¾„ä¸­æå– segment_id å’Œ timestamp
        # è·¯å¾„æ ¼å¼: test_output/{segment_id}/{timestamp}/llm_generated_text.txt
        parts = llm_file.parts
        if len(parts) < 3:
            print(f"âš ï¸ è·³è¿‡æ— æ•ˆè·¯å¾„: {llm_file}")
            continue
        
        segment_id = parts[-3]  # segment_id æ˜¯å€’æ•°ç¬¬ä¸‰éƒ¨åˆ†
        timestamp = parts[-2]   # timestamp æ˜¯å€’æ•°ç¬¬äºŒéƒ¨åˆ†
        
        # è¯»å–æ–‡ä»¶å†…å®¹
        try:
            with open(llm_file, 'r', encoding='utf-8') as f:
                content = f.read().strip()
        except Exception as e:
            print(f"âš ï¸ è¯»å–æ–‡ä»¶å¤±è´¥ {llm_file}: {e}")
            continue
        
        if not content:
            print(f"âš ï¸ æ–‡ä»¶ä¸ºç©º: {llm_file}")
            continue
        
        stats["total_files"] += 1
        
        # é¦–å…ˆå°è¯•ç›´æ¥è§£æåŸå§‹å†…å®¹
        original_parse_success = False
        try:
            json.loads(content)
            original_parse_success = True
            stats["original_parse_success"] += 1
            answer_json_str = content
        except (json.JSONDecodeError, RecursionError):
            # åŸå§‹è§£æå¤±è´¥ï¼Œå°è¯•ä¿®å¤
            try:
                fixed_content = fix_json_string(content)
                
                # æ£€æŸ¥ä¿®å¤åçš„å†…å®¹æ˜¯å¦ä¸åŸå§‹å†…å®¹ä¸åŒ
                is_fixed = (fixed_content != content)
                
                # éªŒè¯ JSON æ˜¯å¦æœ‰æ•ˆ
                try:
                    json.loads(fixed_content)
                    stats["fixed_parse_success"] += 1
                    answer_json_str = fixed_content
                    # if is_fixed:
                    #     print(f"âœ… JSON ä¿®å¤æˆåŠŸ (segment_id={segment_id}, timestamp={timestamp})")
                except (json.JSONDecodeError, RecursionError) as e:
                    stats["parse_failed"] += 1
                    # print(f"âš ï¸ JSON è§£æå¤±è´¥ (segment_id={segment_id}, timestamp={timestamp}): {type(e).__name__}: {str(e)[:100]}")
                    # print(f"   åŸå§‹å†…å®¹å‰100å­—ç¬¦: {content[:100]}")
                    # ä¿®å¤åä»ç„¶è§£æå¤±è´¥ï¼Œä¿å­˜ "error" æ ‡è®°
                    answer_json_str = "error"
            except (RecursionError, Exception) as e:
                stats["parse_failed"] += 1
                # print(f"âš ï¸ JSON ä¿®å¤è¿‡ç¨‹å‡ºé”™ (segment_id={segment_id}, timestamp={timestamp}): {type(e).__name__}: {str(e)[:100]}")
                # print(f"   åŸå§‹å†…å®¹å‰100å­—ç¬¦: {content[:100]}")
                # ä¿®å¤è¿‡ç¨‹å‡ºé”™ï¼Œä¿å­˜ "error" æ ‡è®°
                answer_json_str = "error"
        
        # æ„å»ºé¢„æµ‹æ¡ç›®
        prediction_entry = {
            "sample_idx": sample_idx,
            "segment_id": segment_id,
            "timestamp": timestamp,
            "result": {
                "answer_json_str": answer_json_str,
                "cot": None  # llm_generated_text.txt æ²¡æœ‰ cot
            }
        }
        
        predictions.append(prediction_entry)
        sample_idx += 1

    result["detailed_results"]["predictions"] = predictions
    
    # è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
    print(f"\nğŸ“Š JSON è§£æç»Ÿè®¡:")
    print(f"   æ€»æ–‡ä»¶æ•°: {stats['total_files']}")
    print(f"   åŸå§‹è§£ææˆåŠŸ: {stats['original_parse_success']} å¸§")
    print(f"   ä¿®å¤åè§£ææˆåŠŸ: {stats['fixed_parse_success']} å¸§")
    print(f"   è§£æå¤±è´¥: {stats['parse_failed']} å¸§")
    print(f"âœ… æˆåŠŸæ”¶é›† {len(predictions)} ä¸ªé¢„æµ‹ç»“æœ")
    
    return result

CAMS = ('ring_front_center', 'ring_front_left', 'ring_front_right',
        'ring_rear_left', 'ring_rear_right', 'ring_side_left', 'ring_side_right')
LANE_CLASSES = ('lane_segment', 'ped_crossing')
TE_CLASSES = ('traffic_light', 'road_sign')
TE_ATTR_CLASSES = ('unknown', 'red', 'green', 'yellow',
                    'go_straight', 'turn_left', 'turn_right',
                    'no_left_turn', 'no_right_turn', 'u_turn', 'no_u_turn',
                    'slight_left', 'slight_right')
MAP_CHANGE_LOGS = [
    '75e8adad-50a6-3245-8726-5e612db3d165',
    '54bc6dbc-ebfb-3fba-b5b3-57f88b4b79ca',
    'af170aac-8465-3d7b-82c5-64147e94af7d',
    '6e106cf8-f6dd-38f6-89c8-9be7a71e7275',
]

split = 'val'
points_num = 10

# ä» test_output æ”¶é›† llm_generated_text.txt å¹¶æ±‡æ€»
test_output_dir = "./work_dirs/test_output"

#####æ²¡ç”Ÿæˆçš„è¯ï¼Œè¦è¿è¡Œä¸€æ¬¡è¿™ä¸ª
aggregated_results = collect_llm_results_from_test_output(test_output_dir)

# # ä¿å­˜æ±‡æ€»ç»“æœä¸º JSON æ–‡ä»¶
output_json_path = "./tools/evaluate/llm_results_aggregated.json"
with open(output_json_path, 'w', encoding='utf-8') as f:
    json.dump(aggregated_results, f, indent=2, ensure_ascii=False)
print(f"âœ… æ±‡æ€»ç»“æœå·²ä¿å­˜åˆ°: {output_json_path}")

# æ›´æ–° json_path æŒ‡å‘æ–°ç”Ÿæˆçš„æ–‡ä»¶
json_path = output_json_path

test_all_results(
    eval_json_path=json_path,
    out_dir="vis_results",
    use_select_scenes=USE_SELECT_SCENES,
    select_scenes=scene_id if USE_SELECT_SCENES else None
)

print("âœ… æ‰€æœ‰å¤„ç†å®Œæˆï¼")

# visualize_all_results(
#     eval_json_path="./saves/qwen3vl-2b/lora/topocot_sft/eval_results_20251216_114806qwenvl2b.json",
#     out_dir="vis_results"
# )
